---
title: "Client Report - Project 5"
subtitle: "Course DS 250"
author: "Xave Perry"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
#| label: libraries
#| include: false
import pandas as pd
import numpy as np
import plotly.express as px
import sqlite3
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
```


## Elevator pitch

_Did you know that depending on whether someone is a fan of *Star Wars* or not can be an indicator of the income that someone makes each year? During this project, I was able to clean up data from a survey all about *Star Wars* and use that data in a AI model to predict whether someone made over $50,000 in a year with about 65% accuracy only looking at how they ranked different characters from the franchise! I was surprised to see just how messy data can be when it is first received even with survey data that you would think would be more organized. As you clean up the data one piece of a time you can make a wonderful database that can make awesome predictions!_

```{python}
#| label: project data
#| code-summary: Read and format project data
# Include and execute your code here
# Read the CSV file
# Read the CSV file with a different encoding

df = pd.read_csv("https://raw.githubusercontent.com/fivethirtyeight/data/master/star-wars-survey/StarWars.csv", encoding='latin1')

```

## Fixing Columns Names

__Shorten the column names and clean them up for easier use with pandas. Provide a table or list that exemplifies how you fixed the names.__

_I was able to fix all of the column names by starting with some of the random columns in the data set, then doing the demographic columns, and then renaming the movie columns and the character columns. I found that with how the .csv was set up their were many columns marked as 'unnamed' so I had to find the order that the movies and characters were listed later on in the .csv file to know what each of the unnanmed columns were linked to. I was able to do this with the rename() function in Pandas._

```{python}
#| label: Q1
#| code-summary: Read and format data
# Include and execute your code here

df = df.rename(columns={'RespondentID': 'respondent_id',

'Have you seen any of the 6 films in the Star Wars franchise?': 'seen', 

'Do you consider yourself to be a fan of the Star Wars film franchise?': 'fan',

'"Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her."': 'favorable',

'Which character shot first?': 'shot',

'Are you familiar with the Expanded Universe?': 'exp_uni',

'Do you consider yourself to be a fan of the Expanded Universe?æ': 'fan_exp_uni',

'Do you consider yourself to be a fan of the Star Trek franchise?': 'fan_trek',

'Gender': 'gender',
'Age': 'age',
'Household Income': 'income',
'Education': 'education',
'Location (Census Region)': 'location',

'Which of the following Star Wars films have you seen? Please select all that apply.': 'ep_1',
'Unnamed: 4': "ep_2",
'Unnamed: 5': "ep_3",
'Unnamed: 6': "ep_4",
'Unnamed: 7': "ep_5",
'Unnamed: 8': "ep_6",

'Please rank the Star Wars films in order of preference with 1 being your favorite film in the franchise and 6 being your least favorite film.': 'ep_1_rank',
'Unnamed: 10': 'ep_2_rank',
'Unnamed: 11': 'ep_3_rank',
'Unnamed: 12': 'ep_4_rank',
'Unnamed: 13': 'ep_5_rank',
'Unnamed: 14': 'ep_6_rank',

'Please state whether you view the following characters favorably, unfavorably, or are unfamiliar with him/her.': 'Han Solo',
'Unnamed: 16': 'Luke Skywalker',
'Unnamed: 17': 'Princess Leia Organa',
'Unnamed: 18': 'Anakin Skywalker',
'Unnamed: 19': 'Obi Wan Kenobi',
'Unnamed: 20': 'Emperor Palpatine',
'Unnamed: 21': 'Darth Vader',
'Unnamed: 22': 'Lando Calrissian',
'Unnamed: 23': 'Boba Fett',
'Unnamed: 24': 'C-3P0',
'Unnamed: 25': 'R2 D2',
'Unnamed: 26': 'Jar Jar Binks',
'Unnamed: 27': 'Padme Amidala',
'Unnamed: 28': 'Yoda'})

```

```{python}
#| label: Q1 table
#| code-summary: Display column names
#| tbl-cap: "Column Names"
#| tbl-cap-location: top
# Include and execute your code here

mydat = df.head(0)

display(mydat)

```

## Clean and Prepare Data

__Clean and format the data so that it can be used in a machine learning model. As you format the data, you should complete each item listed below. In your final report provide example(s) of the reformatted data with a short description of the changes made.__

_I was able to clean the data so that an AI model would be able to make predictions on the data to find whether someone made more than $50,000 in income. I included comments showing where I cleaned up each column listed in the description of this project. I also added an additional clean up for each of the character columns because I wanted to do it a specific way for the model to read it rather than just one-hot encoding it. I found that it was pretty easy to clean up the data using the replace() function that Pandas uses to help find specific strings or data types and replaces it with whatever you specify. One-hot encoding is a powerful tool to quickly format categorical data into data usable for AI models. I also decided to filter the data whether any of the movies were a 'yes' on if they had seen it rather than on the general seen column since some of the inputs in the general were marked as 'no', but the movies seen were still marked as a 'yes'._

```{python}
#| label: Q2
#| code-summary: Read and format data
# Include and execute your code here

# Overall clean up
pd.set_option('display.max_columns', None)

df.fillna(0, inplace=True)

df.replace({'Yes': 1, 'No': 0}, inplace=True)

# character clean up
characters_to_modify = ['Han Solo', 'Luke Skywalker', 'Princess Leia Organa', 'Anakin Skywalker', 'Obi Wan Kenobi', 'Emperor Palpatine', 'Darth Vader', 'Lando Calrissian', 'Boba Fett', 'C-3P0', 'R2 D2', 'Jar Jar Binks', 'Padme Amidala', 'Yoda']

for character in characters_to_modify:
    df[character] = df[character].replace({'Very favorably': 5, 'Somewhat favorably': 4, 'Neither favorably nor unfavorably (neutral)': 3, 'Somewhat unfavorably': 2, 'Very unfavorably': 1, 'Unfamiliar (N/A)': 0})

#-------------------------------------------------------

#a. Filter the dataset to respondents that have seen at least one film.
ep_columns_to_modify = ['ep_1', 'ep_2', 'ep_3', 'ep_4', 'ep_5', 'ep_6']

for column in ep_columns_to_modify:
    df[column] = df[column].replace('[^\d]+', 1, regex=True).astype(int)

df = df[(df['seen'] == 1) | (df['seen'] == 0)]

#-------------------------------------------------------

#b. Create a new column that converts the age ranges to a single number. Drop the age range categorical column.
df['age'] = df['age'].replace({'18-29': 18, '30-44': 30, '45-60': 45, '> 60': 60}).astype(int)

#-------------------------------------------------------

#c. Create a new column that converts the education groupings to a single number. Drop the school categorical column
df['education'] = df['education'].replace({'Graduate degree': 5, 'Bachelor degree': 4, 'Some college or Associate degree': 3, 'High school degree': 2, 'Less than high school degree': 1, 0: 4}).astype(int)

#-------------------------------------------------------

#d. Create a new column that converts the income ranges to a single number. Drop the income range categorical column.
df['income'] = df['income'].replace({'$150,000+': 1, '$100,000 - $149,999': 1, '$50,000 - $99,999': 1, '$25,000 - $49,999': 0, '$0 - $24,999': 0, 0: 1}).astype(int)

#-------------------------------------------------------

#e. Create your target (also known as “y” or “label”) column based on the new income range column.
y = df['income']

#-------------------------------------------------------

#f. One-hot encode all remaining categorical columns.
cat_cols = ['shot', 'gender', 'location']

df_encoded = pd.get_dummies(df, columns=cat_cols, dtype=int)

df = df_encoded

```

## Validation of Data

__Validate that the data provided on GitHub lines up with the article by recreating 2 of the visuals from the article.__

_I was able to filter the data down to the same specifications as were used in the article for the most watched films and the best movie of the *Star Wars* Franchise. As I filtered the data to those specifications I also came up with the total numbers of 835 and 471 respondents for the two different graphs. I made sure to put the movie titles on the y axis and the percentages on the x-axis to match the article charts. I also included images of the article charts so that it is easy to compare my results with their results._

```{python}
#| label: Q3
#| code-summary: Read and format data
# Include and execute your code here

with sqlite3.connect('your_database.db') as con:
    # Write DataFrame to SQLite
    df.to_sql('star_data', con, index=False, if_exists='replace')

    q_which_films = '''
    SELECT 
    FLOOR(SUM(ep_1 * 1.0) / COUNT(respondent_id)* 100) AS `The Phantom Menace`,
    FLOOR(SUM(ep_2 * 1.0) / COUNT(respondent_id)* 100) AS `Attack of the Clones`,
    CEILING(SUM(ep_3 * 1.0) / COUNT(respondent_id)* 100) AS `Revenge of the Sith`,
    CEILING(SUM(ep_4 * 1.0) / COUNT(respondent_id)* 100) AS `A New Hope`,
    CEILING(SUM(ep_5 * 1.0) / COUNT(respondent_id)* 100) AS `The Empire Strikes Back`,
    FLOOR(SUM(ep_6 * 1.0) / COUNT(respondent_id)* 100) AS `Return of the Jedi`
    FROM star_data;
    '''
    
    q_best_movie = '''

    SELECT
    CEILING((SUM(CASE
            WHEN ep_1_rank = 1
                THEN 1
                ELSE 0   
        END)* 1.0 / 471) * 100) AS `The Phantom Menace`,
    CEILING((SUM(CASE
            WHEN ep_2_rank = 1
                THEN 1
                ELSE 0   
        END)* 1.0 / 471) * 100) AS `Attack of the Clones`,
    CEILING((SUM(CASE
            WHEN ep_3_rank = 1
                THEN 1
                ELSE 0   
        END)* 1.0 / 471) * 100) AS `Revenge of the Sith`,
    FLOOR((SUM(CASE
            WHEN ep_4_rank = 1
                THEN 1
                ELSE 0   
        END)* 1.0 / 471) * 100) AS `A New Hope`,
    CEILING((SUM(CASE
            WHEN ep_5_rank = 1
                THEN 1
                ELSE 0   
        END)* 1.0 / 471) * 100) AS `The Empire Strikes Back`,
    FLOOR((SUM(CASE
            WHEN ep_6_rank = 1
                THEN 1
                ELSE 0   
        END)* 1.0 / 471) * 100) AS `Return of the Jedi`
    FROM star_data
    WHERE 
    ep_1 = 1 AND 
    ep_2 = 1 AND 
    ep_3 = 1 AND 
    ep_4 = 1 AND 
    ep_5 = 1 AND 
    ep_6 = 1;
    '''

    result_which_films = pd.read_sql_query(q_which_films, con)
    result_best_movie = pd.read_sql_query(q_best_movie, con)

```

_I recreated the article chart inlcuded below with the data after I cleaned it. As you can see the data is still acurate with what the article originally showed._

<img src="films_chart.png" alt="Which Films Chart from Article">

```{python}
#| label: Q3 chart A
#| code-summary: Recreating which films chart from article
#| fig-cap: "Most viewed Films"
#| fig-align: center
# Include and execute your code here

# Reshape the DataFrame into long format
df_which_films = pd.melt(result_which_films, value_vars=['Return of the Jedi', 'The Empire Strikes Back', 'A New Hope', 'Revenge of the Sith', 'Attack of the Clones', 'The Phantom Menace'], var_name='Movie', value_name='Percentage')

# Create a bar chart using Plotly Express
chart = px.bar(df_which_films, 
                x='Percentage', 
                y='Movie', 
                text='Percentage', 
                title="Which 'Star Wars' Movies Have You Seen?")

# Show the chart
chart.show()
```

_I recreated the article chart inlcuded below with the data after I cleaned it. As you can see the data is still acurate with what the article originally showed._

<img src="best_movie.png" alt="Best Movie Chart from Article">

```{python}
#| label: Q3 chart B
#| code-summary: Recreating best movie from article
#| fig-cap: "Best Movie"
#| fig-align: center
# Include and execute your code here

# Reshape the DataFrame into long format
df_which_films = pd.melt(result_best_movie, value_vars=['Return of the Jedi', 'The Empire Strikes Back', 'A New Hope', 'Revenge of the Sith', 'Attack of the Clones', 'The Phantom Menace'], var_name='Movie', value_name='Percentage')

# Create a bar chart using Plotly Express
chart = px.bar(df_which_films, 
                x='Percentage', 
                y='Movie', 
                text='Percentage', 
                title="What's the Best 'Star Wars' Movie?")

# Show the chart
chart.show()
```

## Can *Star Wars* Predict Income?

__Build a machine learning model that predicts whether a person makes more than $50k. Describe your model and report the accuracy.__

_I was surprised to see that based off of the favorability of the different *Star Wars* characters provided in the survey that a model could prediect 60-70% of the time whether someone made over $50,000. It is a large amount of the data, but with how random those rankings are I do not think that I am overloading the model with too much information to skew the results. From the results of this model it seems that if you were to ask someone about their love for these different characters the model could predict their income is over $50k about 65% of the time._

```{python}
#| label: Q4
#| code-summary: Read and format data
# Include and execute your code here

X = df[['Han Solo', 'Luke Skywalker', 'Princess Leia Organa', 'Anakin Skywalker', 'Obi Wan Kenobi', 'Emperor Palpatine', 'Darth Vader', 'Lando Calrissian', 'Boba Fett', 'C-3P0', 'R2 D2', 'Jar Jar Binks', 'Padme Amidala', 'Yoda']]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

```

```{python}
#| label: Q4 Model Results
#| code-summary: Calculate accuracy, conf matrix, class rep
#| fig-cap: "Random Forest Model Results"
#| fig-align: center
# Include and execute your code here

# Initialize the Random Forest model
rf_model = RandomForestClassifier()

# Train the model using the training data
rf_model.fit(X_train, y_train)

# Make predictions on the test data
y_pred_rf = rf_model.predict(X_test)

conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)
classification_rep_rf = classification_report(y_test, y_pred_rf)
accuracy_rf = accuracy_score(y_test, y_pred_rf)

print(accuracy_rf)
print(conf_matrix_rf)
print(classification_rep_rf)
```
